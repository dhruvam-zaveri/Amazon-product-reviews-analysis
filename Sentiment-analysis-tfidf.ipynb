{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\python312\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\python312\\lib\\site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\python312\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install bs4 \n",
    "# in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Beauty_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_21032\\3465206082.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(url, sep='\\t',on_bad_lines='skip')\n"
     ]
    }
   ],
   "source": [
    "url = \"https://web.archive.org/web/20201127142707if_/https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Office_Products_v1_00.tsv.gz\"\n",
    "data = pd.read_csv(url, sep='\\t',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exrtacting the required fields from the dataset\n",
    "data = data[[\"review_body\", \"star_rating\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                   review_body  \\\n",
      "0                                                                                                                                               Great product.   \n",
      "1  What's to say about this commodity item except, what have we come to in this world.<br />Having the need to bnuy captured and compressed air. &#60;lol&#62;   \n",
      "2                                                                                                              Haven't used yet, but I am sure I will like it.   \n",
      "\n",
      "  star_rating  \n",
      "0           5  \n",
      "1           5  \n",
      "2           5  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We form three classes and select 10000 reviews randomly from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews having rating 5 : 1459036\n",
      "Number of reviews having rating 4 : 389612\n",
      "Number of reviews having rating 1 : 286080\n",
      "Number of reviews having rating 3 : 179871\n",
      "Number of reviews having rating 2 : 129033\n",
      "Number of reviews having rating 5 : 123776\n",
      "Number of reviews having rating 4 : 28759\n",
      "Number of reviews having rating 1 : 20899\n",
      "Number of reviews having rating 3 : 13820\n",
      "Number of reviews having rating 2 : 9351\n",
      "Number of reviews having rating 2015-06-05 : 1\n",
      "Number of reviews having rating 2015-02-11 : 1\n",
      "Number of reviews having rating 2014-02-14 : 1\n",
      "\n",
      "\n",
      "Number of reviews having rating 5.0 : 1582704\n",
      "Number of reviews having rating 4.0 : 418348\n",
      "Number of reviews having rating 1.0 : 306967\n",
      "Number of reviews having rating 3.0 : 193680\n",
      "Number of reviews having rating 2.0 : 138381\n",
      "\n",
      "# of Positive rating: 2001052\n",
      "# of Negative rating: 445348\n",
      "# of Neutral rating: 193680\n"
     ]
    }
   ],
   "source": [
    "rating_stats = data.star_rating.value_counts()\n",
    "for i , j in rating_stats.items():\n",
    "    print(f'Number of reviews having rating {i} : {j}')\n",
    "    \n",
    "print()\n",
    "# removing any rating except from 1, 2, 3, 4, and 5. There are some ratings with NaN and string values\n",
    "data.loc[:, 'star_rating'] = pd.to_numeric(data.star_rating, errors=\"coerce\")\n",
    "\n",
    "data = data.dropna()\n",
    "# data[\"star_rating\"] = data[\"star_rating\"].astype(int)\n",
    "print()\n",
    "rating_stats = data.star_rating.value_counts()\n",
    "for i , j in rating_stats.items():\n",
    "    print(f'Number of reviews having rating {i} : {j}')\n",
    "\n",
    "# ignoring all neutral rating (class 3)\n",
    "neutral_rating = data[data[\"star_rating\"] == 3].shape[0]\n",
    "\n",
    "data.drop(data[data.star_rating == 3].index, inplace=True)\n",
    "# data = data[data['star_rating'] != 3]\n",
    "data[\"sentiment\"] = data[\"star_rating\"].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# selecting 100000 reviews from positive and negative class on a raandom basis\n",
    "rating_1 = data[data[\"sentiment\"] == 1].sample(n=100000, random_state=1)\n",
    "rating_0 = data[data[\"sentiment\"] == 0].sample(n=100000, random_state=1)\n",
    "\n",
    "# number of total reviews in each class: positive, negative and neutral\n",
    "positive_rating = data[data[\"sentiment\"] == 1].shape[0]\n",
    "negative_rating = data[data[\"sentiment\"] == 0].shape[0]\n",
    "\n",
    "print(f\"\\n# of Positive rating: {positive_rating}\")\n",
    "print(f\"# of Negative rating: {negative_rating}\")\n",
    "print(f\"# of Neutral rating: {neutral_rating}\")\n",
    "\n",
    "final_sample = pd.concat([rating_0, rating_1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_len_before = final_sample[\"review_body\"].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert reviews to lowercase strings\n",
    "final_sample[\"review_body\"] = final_sample[\"review_body\"].str.lower()\n",
    "\n",
    "# to remove HTML tags\n",
    "final_sample[\"review_body\"] = final_sample[\"review_body\"].apply(lambda text: re.sub(r'<.*?>', '', text)  if type(text) == str else '')\n",
    "\n",
    "# to remove URLs\n",
    "final_sample[\"review_body\"] = final_sample[\"review_body\"].apply(lambda text: re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE))\n",
    "\n",
    "# to remove non-alphabetic characters except for aphostophes as they will be removed by expanding the contractions\n",
    "final_sample[\"review_body\"] = final_sample[\"review_body\"].apply(lambda text: re.sub(r'[^a-z\\s\\']', '', text))\n",
    "\n",
    "# to remove extra spaces\n",
    "final_sample[\"review_body\"] = final_sample[\"review_body\"].apply(lambda text: re.sub(r'\\s+', ' ', text).strip())\n",
    "\n",
    "# contractions dictionary for expanding the same. For contractions with multiple expansion I have taken the ones that fit most closely according to me. \n",
    "contractions_dict = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"I would\",\n",
    "    \"i'd've\": \"I would have\",\n",
    "    \"i'll\": \"I will\",\n",
    "    \"i'll've\": \"I will have\",\n",
    "    \"i'm\": \"I am\",\n",
    "    \"i've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "# expanding contractions\n",
    "final_sample[\"review_body\"] = final_sample[\"review_body\"].apply(lambda text: ' '.join([contractions_dict[word] if word in contractions_dict else word for word in text.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of reviews before and after data cleaning: 317.722825, 301.98912\n"
     ]
    }
   ],
   "source": [
    "avg_len_after = final_sample[\"review_body\"].apply(len).mean()\n",
    "print(f\"Average length of reviews before and after data cleaning: {avg_len_before}, {avg_len_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        review_body  \\\n",
      "2081506                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           item arrived pictured delivered brown box green mountain stamp contained different kinds coffee's kind company never responded several emails phone calls ionly got refund filed complaint amazon   \n",
      "413128                                                                                                                                                                                                phones look nice plenty extras lack ability make basic phone enjoyable opening setting following instructions set enjoy phone set came problem anyone end line unable understand even hear get cannot hear hello tried using speaker phone tried calling people got results time either static voice total silence caller tried phones issues know house phone line phones totally unacceptable brand problem especially price returning set amazon since amazon always awesome comes returns faulty products worries amazon still get money different phone set guess product always gamble happens one lost   \n",
      "2626383  c stopped working completely days installed apparently power supply went bad could get power spending half hour phone dimelong distance hp provide toll free service number waiting speak technician told first thing would send new power cord even though clearly problem wait weeks shipped power cord turned solve problem decided send new unit arrived today thing came box printer print cartridges see expected remove print cartridges original printer place new unit possible since locked place underneath part printer housing original technician told case finished another call dime hp told could ship another set cartridges would arrive business days hooray eight weeks since purchased dog printer still cannot print job pack old printer find fedex drop site get old printer back   \n",
      "1808780                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            thought epson ink epson cartridges machine five warnings told warranty would void use product amazing amazon would offer product   \n",
      "2519766                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   got palm z gift say thank god waste money windows vista bit palm os work spent wasted hours trying find solution problem avail palm warn workbut super fine print go palm website tells program come work   \n",
      "\n",
      "        star_rating  sentiment  \n",
      "2081506         1.0          0  \n",
      "413128          2.0          0  \n",
      "2626383         1.0          0  \n",
      "1808780         1.0          0  \n",
      "2519766         1.0          0  \n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords_en = stopwords.words('english')\n",
    "\n",
    "avg_len_before = data[\"review_body\"].apply(len).mean()\n",
    "\n",
    "# removing stop words\n",
    "# final_sample[\"review_body\"] = final_sample[\"review_body\"].apply(lambda text: ' '.join([word if word not in stopwords_en else '' for word in text.split()]))\n",
    "final_sample[\"review_body\"] = final_sample[\"review_body\"].apply( lambda x : ' '.join([i for i in x.split() if i not in (stopwords_en)]))\n",
    "\n",
    "print(final_sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average length of reviews before and after data cleaning: 279.14, 191.664955\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from collections import defaultdict\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# creating a pos tag map for proper lemmatization\n",
    "pos_tag_map = defaultdict(lambda : wn.NOUN)\n",
    "pos_tag_map['J'] = wn.ADJ\n",
    "pos_tag_map['V'] = wn.VERB\n",
    "pos_tag_map['R'] = wn.ADV\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# for each review: we would contextually tokenize the sentence using word_tokenize, this will give us the word token and it's pos_tag. This tag will be mapped with pos_tag_map to get the appropriate wordnet pos_tag that will be feed into the lemmatizer.\n",
    "final_sample[\"review_lemmatize\"] = final_sample[\"review_body\"].apply(lambda text: ' '.join([lemmatizer.lemmatize(word_token, pos_tag_map[word_pos_tag[0]])\n",
    " for word_token, word_pos_tag in pos_tag(word_tokenize(text))]))\n",
    "\n",
    "avg_len_after = final_sample[\"review_body\"].apply(len).mean()\n",
    "print(f\"\\nAverage length of reviews before and after data cleaning: {round(avg_len_before, 2)}, {avg_len_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   review_lemmatize  \\\n",
      "2081506                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     item arrive pictured deliver brown box green mountain stamp contain different kind coffee 's kind company never respond several email phone call ionly get refund file complaint amazon   \n",
      "413128                                                                                                                                                                                                    phone look nice plenty extra lack ability make basic phone enjoyable open set follow instruction set enjoy phone set come problem anyone end line unable understand even hear get can not hear hello try use speaker phone try call people get result time either static voice total silence caller try phone issue know house phone line phone totally unacceptable brand problem especially price return set amazon since amazon always awesome come return faulty product worry amazon still get money different phone set guess product always gamble happen one lost   \n",
      "2626383  c stop work completely day instal apparently power supply go bad could get power spending half hour phone dimelong distance hp provide toll free service number wait speak technician tell first thing would send new power cord even though clearly problem wait week ship power cord turn solve problem decide send new unit arrive today thing come box printer print cartridge see expect remove print cartridge original printer place new unit possible since locked place underneath part printer housing original technician tell case finish another call dime hp tell could ship another set cartridge would arrive business day hooray eight week since purchase dog printer still can not print job pack old printer find fedex drop site get old printer back   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        review_body  \n",
      "2081506                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           item arrived pictured delivered brown box green mountain stamp contained different kinds coffee's kind company never responded several emails phone calls ionly got refund filed complaint amazon  \n",
      "413128                                                                                                                                                                                                phones look nice plenty extras lack ability make basic phone enjoyable opening setting following instructions set enjoy phone set came problem anyone end line unable understand even hear get cannot hear hello tried using speaker phone tried calling people got results time either static voice total silence caller tried phones issues know house phone line phones totally unacceptable brand problem especially price returning set amazon since amazon always awesome comes returns faulty products worries amazon still get money different phone set guess product always gamble happens one lost  \n",
      "2626383  c stopped working completely days installed apparently power supply went bad could get power spending half hour phone dimelong distance hp provide toll free service number waiting speak technician told first thing would send new power cord even though clearly problem wait weeks shipped power cord turned solve problem decided send new unit arrived today thing came box printer print cartridges see expected remove print cartridges original printer place new unit possible since locked place underneath part printer housing original technician told case finished another call dime hp told could ship another set cartridges would arrive business days hooray eight weeks since purchased dog printer still cannot print job pack old printer find fedex drop site get old printer back  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "print(final_sample[[\"review_lemmatize\", \"review_body\"]].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aa  aaa  aaa battery   ability  able  able find  able get  able print  \\\n",
      "0  0.0  0.0          0.0  0.000000   0.0        0.0       0.0         0.0   \n",
      "1  0.0  0.0          0.0  0.097509   0.0        0.0       0.0         0.0   \n",
      "2  0.0  0.0          0.0  0.000000   0.0        0.0       0.0         0.0   \n",
      "3  0.0  0.0          0.0  0.000000   0.0        0.0       0.0         0.0   \n",
      "4  0.0  0.0          0.0  0.000000   0.0        0.0       0.0         0.0   \n",
      "\n",
      "   able use  absolute  ...  yield  young  youtube   yr  zebra  zero  \\\n",
      "0       0.0       0.0  ...    0.0    0.0      0.0  0.0    0.0   0.0   \n",
      "1       0.0       0.0  ...    0.0    0.0      0.0  0.0    0.0   0.0   \n",
      "2       0.0       0.0  ...    0.0    0.0      0.0  0.0    0.0   0.0   \n",
      "3       0.0       0.0  ...    0.0    0.0      0.0  0.0    0.0   0.0   \n",
      "4       0.0       0.0  ...    0.0    0.0      0.0  0.0    0.0   0.0   \n",
      "\n",
      "   zero star  zip  zipper  zire  \n",
      "0        0.0  0.0     0.0   0.0  \n",
      "1        0.0  0.0     0.0   0.0  \n",
      "2        0.0  0.0     0.0   0.0  \n",
      "3        0.0  0.0     0.0   0.0  \n",
      "4        0.0  0.0     0.0   0.0  \n",
      "\n",
      "[5 rows x 5000 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
    "tfidf_features = tfidf_vectorizer.fit_transform(final_sample[\"review_lemmatize\"].tolist())\n",
    "\n",
    "# to get the features that the vectorizer selected \n",
    "feature_df = pd.DataFrame(tfidf_features.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "# final_df = pd.concat([feature_df, final_sample])\n",
    "\n",
    "print(feature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = feature_df\n",
    "y = final_sample[\"sentiment\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Accuracy: 0.8590875\n",
      "Precision: 0.9488397531057113\n",
      "Recall: 0.759078919405448\n",
      "F1 Score: 0.8434175070144734\n",
      "\n",
      "Testing Metrics:\n",
      "Accuracy: 0.85105\n",
      "Precision: 0.9386748267033036\n",
      "Recall: 0.7512870495326636\n",
      "F1 Score: 0.8345918933925597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Initialize the Perceptron model\n",
    "perceptron = Perceptron()\n",
    "\n",
    "# Train the model\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = perceptron.predict(X_train)\n",
    "y_test_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Calculate metrics for training data\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for testing data\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1 Score:\", f1_train)\n",
    "\n",
    "print(\"\\nTesting Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Accuracy: 0.90476875\n",
      "Precision: 0.9091023956332761\n",
      "Recall: 0.8994537021989424\n",
      "F1 Score: 0.9042523109019273\n",
      "\n",
      "Testing Metrics:\n",
      "Accuracy: 0.898125\n",
      "Precision: 0.9030968525452889\n",
      "Recall: 0.8920377867746289\n",
      "F1 Score: 0.8975332545449972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for the testing set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1 Score:\", f1_train)\n",
    "\n",
    "print(\"\\nTesting Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Accuracy: 0.908825\n",
      "Precision: 0.9113780740927102\n",
      "Recall: 0.9057042491217981\n",
      "F1 Score: 0.9085323033707865\n",
      "\n",
      "Testing Metrics:\n",
      "Accuracy: 0.896275\n",
      "Precision: 0.8990437845998993\n",
      "Recall: 0.8928874893787174\n",
      "F1 Score: 0.8959550618150813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = LinearSVC(dual=True)\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred = svm.predict(X_train)\n",
    "y_test_pred = svm.predict(X_test)\n",
    "\n",
    "# Calculate metrics for training data\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for testing data\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1 Score:\", f1_train)\n",
    "\n",
    "print(\"\\nTesting Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Accuracy: 0.86659375\n",
      "Precision: 0.864345708463794\n",
      "Recall: 0.8696510944707662\n",
      "F1 Score: 0.8669902852122111\n",
      "\n",
      "Testing Metrics:\n",
      "Accuracy: 0.864775\n",
      "Precision: 0.8625571229882774\n",
      "Recall: 0.8679462188234118\n",
      "F1 Score: 0.8652432796033782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training and testing sets\n",
    "y_train_pred = nb_model.predict(X_train)\n",
    "y_test_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for the training set\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate metrics for the testing set\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Training Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1 Score:\", f1_train)\n",
    "\n",
    "print(\"\\nTesting Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
